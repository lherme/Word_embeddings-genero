{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consolidando arquivos de extração em um único dataframe\n",
    "\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "stock_files = glob.glob('/Users/guilhermenomelini/Documents/MBA - Data Science/TCC/Extracao/Data/Extracao_*.csv')\n",
    "df = pd.concat((pd.read_csv(file, sep=\";\", encoding=\"utf-8\") for file in stock_files), ignore_index=True)\n",
    "\n",
    "df.assign(vetor_cbow50 = np.nan, vetor_cbow100 = np.nan, vetor_cbow300 = np.nan, vetor_skip50 = np.nan, vetor_skip100 = np.nan, vetor_skip300 = np.nan, cosine_cbow50_fem = np.nan, cosine_cbow50_masc = np.nan, cosine_cbow100_fem = np.nan, cosine_cbow100_masc = np.nan, cosine_cbow300_fem = np.nan, cosine_cbow300_masc = np.nan, cosine_skip50_fem = np.nan, cosine_skip50_masc = np.nan, cosine_skip100_fem = np.nan, cosine_skip100_masc = np.nan, cosine_skip300_fem = np.nan, cosine_skip300_masc = np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deletando vagas duplicadas pela chave Descrição + Empresa + Título + Localidade\n",
    "\n",
    "df = df.drop_duplicates(subset=['Descricao', 'Empresa', 'Titulo', 'Localidade'], keep='first')\n",
    "df.index = pd.RangeIndex(len(df.index))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando word embeddings Word2Vec (NILC)\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "model_cbow50 = KeyedVectors.load_word2vec_format('/Users/guilhermenomelini/Documents/MBA - Data Science/TCC/Modelos/cbow_s50.txt')\n",
    "model_cbow100 = KeyedVectors.load_word2vec_format('/Users/guilhermenomelini/Documents/MBA - Data Science/TCC/Modelos/cbow_s100.txt')\n",
    "model_cbow300 = KeyedVectors.load_word2vec_format('/Users/guilhermenomelini/Documents/MBA - Data Science/TCC/Modelos/cbow_s300.txt')\n",
    "model_skip50 = KeyedVectors.load_word2vec_format('/Users/guilhermenomelini/Documents/MBA - Data Science/TCC/Modelos/skip_s50.txt')\n",
    "model_skip100 = KeyedVectors.load_word2vec_format('/Users/guilhermenomelini/Documents/MBA - Data Science/TCC/Modelos/skip_s100.txt')\n",
    "model_skip300 = KeyedVectors.load_word2vec_format('/Users/guilhermenomelini/Documents/MBA - Data Science/TCC/Modelos/skip_s300.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import tokenize\n",
    "from nltk.tokenize import WhitespaceTokenizer\n",
    "import re\n",
    "\n",
    "# Definindo caracteres de pontuação para remoção\n",
    "char_remov = ['!', '(', ')', '[', ']', '{', '}', ';', ',', '\"', ':', '/', '.', '<', '>', '?', '@', '#', '$', '%', '^', '&', '*', '_', '~', '•', '|', '``', \"''\", '+', '°', 'ª']\n",
    "\n",
    "# Função para deletar emojis\n",
    "def deEmojify(text):\n",
    "    regrex_pattern = re.compile(pattern = \"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           \"]+\", flags = re.UNICODE)\n",
    "    return regrex_pattern.sub(r'',text)\n",
    "\n",
    "# Definindo variável de referência para classe WhitespaceTokenizer\n",
    "tk = WhitespaceTokenizer()\n",
    "\n",
    "# Tokenizing\n",
    "description = []\n",
    "for i in range(len(df)):\n",
    "    descricao_tratada = []\n",
    "    deEmojify(df.Descricao[i])\n",
    "    tokens = tokenize.word_tokenize(df.Descricao[i], language='portuguese')\n",
    "    words_lower_case = [w.lower() for w in tokens] #transformando maiúsculas em minúsculas\n",
    "    filtered_string = [re.sub(r'[0-9]', '', w) for w in words_lower_case] #removendo números\n",
    "    for j in range(len(filtered_string)):\n",
    "        for k in filtered_string[j]:\n",
    "            for char in char_remov: #substituindo os caracteres especiais por espaço\n",
    "                filtered_string[j] = filtered_string[j].replace(char, \" \")\n",
    "        t = tk.tokenize(filtered_string[j]) #quebrando token em novos tokens tendo espaço como separador\n",
    "        if len(t) > 0:\n",
    "            for k in t:\n",
    "                descricao_tratada.append(k)\n",
    "    descricao_tratada = [e for e in descricao_tratada if e not in ('h', ' ', '')]\n",
    "    description.append(descricao_tratada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo função que vetoriza as descrições de emprego\n",
    "\n",
    "def vetorize(modelo, dimensao):\n",
    "    vetor_avg = []\n",
    "    nova_coluna = 'vetor_' + modelo + str(dimensao)\n",
    "    #CBOW-50\n",
    "    if modelo == 'cbow' and dimensao == 50:\n",
    "        for i in range(len(description)): # Loop sobre todas as descrições de emprego\n",
    "            vetor_descricao = np.empty([len(description[i]), 50])\n",
    "            vetor_descricao[:] = np.nan\n",
    "            for j in range(len(description[i])): # Loop para vetorizar cada um dos tokens da descrição de emprego\n",
    "                if description[i][j] in model_cbow50.key_to_index:\n",
    "                    vetor_descricao[j] = model_cbow50[description[i][j]].astype('float64')\n",
    "                else:\n",
    "                    vetor_descricao[j] = np.empty((1,50,))\n",
    "            avg_vetor_descricao = np.nanmean(vetor_descricao.astype('float64'), axis=0) # Vetorização da descrição de emprego = Cálculo da média dos vetores de todos os tokens da descrição\n",
    "            # avg_vetor_descricao = np.nanmean(vetor_descricao, axis=0)\n",
    "            vetor_avg.append(avg_vetor_descricao)\n",
    "    #CBOW-100\n",
    "    elif modelo == 'cbow' and dimensao == 100:\n",
    "        for i in range(len(description)): # Loop sobre todas as descrições de emprego\n",
    "            vetor_descricao = np.empty([len(description[i]), 100])\n",
    "            vetor_descricao[:] = np.nan\n",
    "            for j in range(len(description[i])): # Loop para vetorizar cada um dos tokens da descrição de emprego\n",
    "                if description[i][j] in model_cbow100.key_to_index:\n",
    "                    vetor_descricao[j] = model_cbow100[description[i][j]].astype('float64')\n",
    "                else:\n",
    "                    vetor_descricao[j] = np.empty((1,100,))\n",
    "            avg_vetor_descricao = np.nanmean(vetor_descricao.astype('float64'), axis=0) # Vetorização da descrição de emprego = Cálculo da média dos vetores de todos os tokens da descrição\n",
    "            # avg_vetor_descricao = np.nanmean(vetor_descricao, axis=0)\n",
    "            vetor_avg.append(avg_vetor_descricao)\n",
    "    #CBOW-300\n",
    "    elif modelo == 'cbow' and dimensao == 300:\n",
    "        for i in range(len(description)): # Loop sobre todas as descrições de emprego\n",
    "            vetor_descricao = np.empty([len(description[i]), 300])\n",
    "            vetor_descricao[:] = np.nan\n",
    "            for j in range(len(description[i])): # Loop para vetorizar cada um dos tokens da descrição de emprego\n",
    "                if description[i][j] in model_cbow300.key_to_index:\n",
    "                    vetor_descricao[j] = model_cbow300[description[i][j]].astype('float64')\n",
    "                else:\n",
    "                    vetor_descricao[j] = np.empty((1,300,))\n",
    "            avg_vetor_descricao = np.nanmean(vetor_descricao.astype('float64'), axis=0) # Vetorização da descrição de emprego = Cálculo da média dos vetores de todos os tokens da descrição\n",
    "            # avg_vetor_descricao = np.nanmean(vetor_descricao, axis=0)\n",
    "            vetor_avg.append(avg_vetor_descricao)\n",
    "    #Skip-gram-50\n",
    "    elif modelo == 'skip' and dimensao == 50:\n",
    "        for i in range(len(description)): # Loop sobre todas as descrições de emprego\n",
    "            vetor_descricao = np.empty([len(description[i]), 50])\n",
    "            vetor_descricao[:] = np.nan\n",
    "            for j in range(len(description[i])): # Loop para vetorizar cada um dos tokens da descrição de emprego\n",
    "                if description[i][j] in model_skip50.key_to_index:\n",
    "                    vetor_descricao[j] = model_skip50[description[i][j]].astype('float64')\n",
    "                else:\n",
    "                    vetor_descricao[j] = np.empty((1,50,))\n",
    "            avg_vetor_descricao = np.nanmean(vetor_descricao.astype('float64'), axis=0) # Vetorização da descrição de emprego = Cálculo da média dos vetores de todos os tokens da descrição\n",
    "            # avg_vetor_descricao = np.nanmean(vetor_descricao, axis=0)\n",
    "            vetor_avg.append(avg_vetor_descricao)\n",
    "    #Skip-gram-100\n",
    "    elif modelo == 'skip' and dimensao == 100:\n",
    "        for i in range(len(description)): # Loop sobre todas as descrições de emprego\n",
    "            vetor_descricao = np.empty([len(description[i]), 100])\n",
    "            vetor_descricao[:] = np.nan\n",
    "            for j in range(len(description[i])): # Loop para vetorizar cada um dos tokens da descrição de emprego\n",
    "                if description[i][j] in model_skip100.key_to_index:\n",
    "                    vetor_descricao[j] = model_skip100[description[i][j]].astype('float64')\n",
    "                else:\n",
    "                    vetor_descricao[j] = np.empty((1,100,))\n",
    "            avg_vetor_descricao = np.nanmean(vetor_descricao.astype('float64'), axis=0) # Vetorização da descrição de emprego = Cálculo da média dos vetores de todos os tokens da descrição\n",
    "            # avg_vetor_descricao = np.nanmean(vetor_descricao, axis=0)\n",
    "            vetor_avg.append(avg_vetor_descricao)\n",
    "    #Skip-gram-300\n",
    "    elif modelo == 'skip' and dimensao == 300:\n",
    "        for i in range(len(description)): # Loop sobre todas as descrições de emprego\n",
    "            vetor_descricao = np.empty([len(description[i]), 300])\n",
    "            vetor_descricao[:] = np.nan\n",
    "            for j in range(len(description[i])): # Loop para vetorizar cada um dos tokens da descrição de emprego\n",
    "                if description[i][j] in model_skip300.key_to_index:\n",
    "                    vetor_descricao[j] = model_skip300[description[i][j]].astype('float64')\n",
    "                else:\n",
    "                    vetor_descricao[j] = np.empty((1,300,))\n",
    "            avg_vetor_descricao = np.nanmean(vetor_descricao.astype('float64'), axis=0) # Vetorização da descrição de emprego = Cálculo da média dos vetores de todos os tokens da descrição\n",
    "            # avg_vetor_descricao = np.nanmean(vetor_descricao, axis=0)\n",
    "            vetor_avg.append(avg_vetor_descricao)\n",
    "\n",
    "    else:\n",
    "        print(\"Modelo ou dimensão não permitidos\")\n",
    "\n",
    "    df[nova_coluna] = pd.Series(vetor_avg).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chamando a função de vetorização para cada arquitetura e dimensionalidade\n",
    "\n",
    "vetorize('cbow', 50)\n",
    "vetorize('cbow', 100)\n",
    "vetorize('cbow', 300)\n",
    "vetorize('skip', 50)\n",
    "vetorize('skip', 100)\n",
    "vetorize('skip', 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo os vetores de gênero feminino e masculino\n",
    "\n",
    "# Vetores originais\n",
    "feminino = ['ela', 'elas', 'filha', 'filhas', 'dela', 'delas', 'mãe', 'mães', 'mulher', 'mulheres', 'garota', 'garotas', 'menina', 'meninas', 'feminino', 'femininos', 'fêmea', 'fêmeas', 'irmã', 'irmãs', 'tia', 'tias', 'sobrinha', 'sobrinhas']\n",
    "masculino = ['ele', 'eles', 'filho', 'filhos', 'dele', 'deles', 'pai', 'pais', 'homem', 'homens', 'garoto', 'garotos', 'menino', 'meninos', 'masculino', 'masculinos', 'macho', 'machos', 'irmão', 'irmãos', 'tio', 'tios', 'sobrinho', 'sobrinhos']\n",
    "\n",
    "# Vetores acrescidos de pronomes\n",
    "# feminino = ['ela', 'elas', 'filha', 'filhas', 'dela', 'delas', 'mãe', 'mães', 'mulher', 'mulheres', 'garota', 'garotas', 'menina', 'meninas', 'feminino', 'femininos', 'fêmea', 'fêmeas', 'irmã', 'irmãs', 'tia', 'tias', 'sobrinha', 'sobrinhas',\n",
    "#             \"nela\", \"esta\", \"desta\", \"nesta\", \"essa\", \"dessa\", \"nessa\", \"aquela\", \"daquela\", \"naquela\", \"praquela\",\n",
    "#             \"nelas\", \"estas\", \"destas\", \"nestas\", \"essas\", \"dessas\", \"nessas\", \"aquelas\", \"daquelas\", \"naquelas\", \"praquelas\"]\n",
    "# masculino = ['ele', 'eles', 'filho', 'filhos', 'dele', 'deles', 'pai', 'pais', 'homem', 'homens', 'garoto', 'garotos', 'menino', 'meninos', 'masculino', 'masculinos', 'macho', 'machos', 'irmão', 'irmãos', 'tio', 'tios', 'sobrinho', 'sobrinhos',\n",
    "#             \"nele\", \"este\", \"deste\", \"neste\", \"esse\", \"desse\", \"nesse\", \"aquele\", \"daquele\", \"naquele\", \"praquele\",\n",
    "#             \"neles\", \"estes\", \"destes\", \"nestes\", \"esses\", \"desses\", \"nesses\", \"aqueles\", \"daqueles\", \"naqueles\", \"praqueles\"]\n",
    "\n",
    "# Vetores reduzidos\n",
    "#feminino = ['ela', 'mulher', 'garota', 'menina', 'feminino', 'fêmea']\n",
    "#masculino = ['ele', 'homem', 'garoto', 'menino', 'masculino', 'macho']\n",
    "\n",
    "# Vetores unitários\n",
    "# feminino = ['mulher']\n",
    "# masculino = ['homem']\n",
    "\n",
    "\n",
    "#Criando vetores de gênero feminino\n",
    "\n",
    "#FEM CBOW50\n",
    "vetor_genero_fem_cbow50 = []\n",
    "\n",
    "vetor_descricao = np.empty([len(feminino), 50])\n",
    "vetor_descricao[:] = np.nan\n",
    "for j in range(len(feminino)):\n",
    "    if feminino[j] in model_cbow50.key_to_index:\n",
    "        vetor_descricao[j] = model_cbow50[feminino[j]].astype('float64')\n",
    "    else:\n",
    "        vetor_descricao[j] = np.empty((1,50))\n",
    "avg_vetor_descricao = np.nanmean(vetor_descricao.astype('float64'), axis=0)\n",
    "avg_vetor_descricao = np.nanmean(vetor_descricao, axis=0)\n",
    "vetor_genero_fem_cbow50.append(avg_vetor_descricao)\n",
    "vetor_genero_fem_cbow50 = np.array(vetor_genero_fem_cbow50)\n",
    "\n",
    "\n",
    "\n",
    "#FEM CBOW100\n",
    "vetor_genero_fem_cbow100 = []\n",
    "\n",
    "vetor_descricao = np.empty([len(feminino), 100])\n",
    "vetor_descricao[:] = np.nan\n",
    "for j in range(len(feminino)):\n",
    "    if feminino[j] in model_cbow100.key_to_index:\n",
    "        vetor_descricao[j] = model_cbow100[feminino[j]].astype('float64')\n",
    "    else:\n",
    "        vetor_descricao[j] = np.empty((1,100))\n",
    "avg_vetor_descricao = np.nanmean(vetor_descricao.astype('float64'), axis=0)\n",
    "avg_vetor_descricao = np.nanmean(vetor_descricao, axis=0)\n",
    "vetor_genero_fem_cbow100.append(avg_vetor_descricao)\n",
    "vetor_genero_fem_cbow100 = np.array(vetor_genero_fem_cbow100)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#FEM CBOW300\n",
    "vetor_genero_fem_cbow300 = []\n",
    "\n",
    "vetor_descricao = np.empty([len(feminino), 300])\n",
    "vetor_descricao[:] = np.nan\n",
    "for j in range(len(feminino)):\n",
    "    if feminino[j] in model_cbow300.key_to_index:\n",
    "        vetor_descricao[j] = model_cbow300[feminino[j]].astype('float64')\n",
    "    else:\n",
    "        vetor_descricao[j] = np.empty((1,300))\n",
    "avg_vetor_descricao = np.nanmean(vetor_descricao.astype('float64'), axis=0)\n",
    "avg_vetor_descricao = np.nanmean(vetor_descricao, axis=0)\n",
    "vetor_genero_fem_cbow300.append(avg_vetor_descricao)\n",
    "vetor_genero_fem_cbow300 = np.array(vetor_genero_fem_cbow300)\n",
    "\n",
    "\n",
    "\n",
    "#FEM SKIP50\n",
    "vetor_genero_fem_skip50 = []\n",
    "\n",
    "vetor_descricao = np.empty([len(feminino), 50])\n",
    "vetor_descricao[:] = np.nan\n",
    "for j in range(len(feminino)):\n",
    "    if feminino[j] in model_skip50.key_to_index:\n",
    "        vetor_descricao[j] = model_skip50[feminino[j]].astype('float64')\n",
    "    else:\n",
    "        vetor_descricao[j] = np.empty((1,50))\n",
    "avg_vetor_descricao = np.nanmean(vetor_descricao.astype('float64'), axis=0)\n",
    "avg_vetor_descricao = np.nanmean(vetor_descricao, axis=0)\n",
    "vetor_genero_fem_skip50.append(avg_vetor_descricao)\n",
    "vetor_genero_fem_skip50 = np.array(vetor_genero_fem_skip50)\n",
    "\n",
    "\n",
    "\n",
    "#FEM SKIP100\n",
    "vetor_genero_fem_skip100 = []\n",
    "\n",
    "vetor_descricao = np.empty([len(feminino), 100])\n",
    "vetor_descricao[:] = np.nan\n",
    "for j in range(len(feminino)):\n",
    "    if feminino[j] in model_skip100.key_to_index:\n",
    "        vetor_descricao[j] = model_skip100[feminino[j]].astype('float64')\n",
    "    else:\n",
    "        vetor_descricao[j] = np.empty((1,100))\n",
    "avg_vetor_descricao = np.nanmean(vetor_descricao.astype('float64'), axis=0)\n",
    "avg_vetor_descricao = np.nanmean(vetor_descricao, axis=0)\n",
    "vetor_genero_fem_skip100.append(avg_vetor_descricao)\n",
    "vetor_genero_fem_skip100 = np.array(vetor_genero_fem_skip100)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#FEM SKIP300\n",
    "vetor_genero_fem_skip300 = []\n",
    "\n",
    "vetor_descricao = np.empty([len(feminino), 300])\n",
    "vetor_descricao[:] = np.nan\n",
    "for j in range(len(feminino)):\n",
    "    if feminino[j] in model_skip300.key_to_index:\n",
    "        vetor_descricao[j] = model_skip300[feminino[j]].astype('float64')\n",
    "    else:\n",
    "        vetor_descricao[j] = np.empty((1,300))\n",
    "avg_vetor_descricao = np.nanmean(vetor_descricao.astype('float64'), axis=0)\n",
    "avg_vetor_descricao = np.nanmean(vetor_descricao, axis=0)\n",
    "vetor_genero_fem_skip300.append(avg_vetor_descricao)\n",
    "vetor_genero_fem_skip300 = np.array(vetor_genero_fem_skip300)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Criando vetores de gênero masculino\n",
    "\n",
    "#MASCCBOW50\n",
    "vetor_genero_masc_cbow50 = []\n",
    "\n",
    "vetor_descricao = np.empty([len(masculino), 50])\n",
    "vetor_descricao[:] = np.nan\n",
    "for j in range(len(masculino)):\n",
    "    if feminino[j] in model_cbow50.key_to_index:\n",
    "        vetor_descricao[j] = model_cbow50[masculino[j]].astype('float64')\n",
    "    else:\n",
    "        vetor_descricao[j] = np.empty((1,50))\n",
    "avg_vetor_descricao = np.nanmean(vetor_descricao.astype('float64'), axis=0)\n",
    "avg_vetor_descricao = np.nanmean(vetor_descricao, axis=0)\n",
    "vetor_genero_masc_cbow50.append(avg_vetor_descricao)\n",
    "vetor_genero_masc_cbow50 = np.array(vetor_genero_masc_cbow50)\n",
    "\n",
    "\n",
    "\n",
    "#MASC CBOW100\n",
    "vetor_genero_masc_cbow100 = []\n",
    "\n",
    "vetor_descricao = np.empty([len(masculino), 100])\n",
    "vetor_descricao[:] = np.nan\n",
    "for j in range(len(masculino)):\n",
    "    if feminino[j] in model_cbow100.key_to_index:\n",
    "        vetor_descricao[j] = model_cbow100[masculino[j]].astype('float64')\n",
    "    else:\n",
    "        vetor_descricao[j] = np.empty((1,100))\n",
    "avg_vetor_descricao = np.nanmean(vetor_descricao.astype('float64'), axis=0)\n",
    "avg_vetor_descricao = np.nanmean(vetor_descricao, axis=0)\n",
    "vetor_genero_masc_cbow100.append(avg_vetor_descricao)\n",
    "vetor_genero_masc_cbow100 = np.array(vetor_genero_masc_cbow100)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#MASC CBOW300\n",
    "vetor_genero_masc_cbow300 = []\n",
    "\n",
    "vetor_descricao = np.empty([len(masculino), 300])\n",
    "vetor_descricao[:] = np.nan\n",
    "for j in range(len(masculino)):\n",
    "    if feminino[j] in model_cbow300.key_to_index:\n",
    "        vetor_descricao[j] = model_cbow300[masculino[j]].astype('float64')\n",
    "    else:\n",
    "        vetor_descricao[j] = np.empty((1,300))\n",
    "avg_vetor_descricao = np.nanmean(vetor_descricao.astype('float64'), axis=0)\n",
    "avg_vetor_descricao = np.nanmean(vetor_descricao, axis=0)\n",
    "vetor_genero_masc_cbow300.append(avg_vetor_descricao)\n",
    "vetor_genero_masc_cbow300 = np.array(vetor_genero_masc_cbow300)\n",
    "\n",
    "\n",
    "\n",
    "#MASC SKIP50\n",
    "vetor_genero_masc_skip50 = []\n",
    "\n",
    "vetor_descricao = np.empty([len(masculino), 50])\n",
    "vetor_descricao[:] = np.nan\n",
    "for j in range(len(masculino)):\n",
    "    if feminino[j] in model_skip50.key_to_index:\n",
    "        vetor_descricao[j] = model_skip50[masculino[j]].astype('float64')\n",
    "    else:\n",
    "        vetor_descricao[j] = np.empty((1,50))\n",
    "avg_vetor_descricao = np.nanmean(vetor_descricao.astype('float64'), axis=0)\n",
    "avg_vetor_descricao = np.nanmean(vetor_descricao, axis=0)\n",
    "vetor_genero_masc_skip50.append(avg_vetor_descricao)\n",
    "vetor_genero_masc_skip50 = np.array(vetor_genero_masc_skip50)\n",
    "\n",
    "\n",
    "\n",
    "#MASC SKIP100\n",
    "vetor_genero_masc_skip100 = []\n",
    "\n",
    "vetor_descricao = np.empty([len(masculino), 100])\n",
    "vetor_descricao[:] = np.nan\n",
    "for j in range(len(masculino)):\n",
    "    if feminino[j] in model_skip100.key_to_index:\n",
    "        vetor_descricao[j] = model_skip100[masculino[j]].astype('float64')\n",
    "    else:\n",
    "        vetor_descricao[j] = np.empty((1,100))\n",
    "avg_vetor_descricao = np.nanmean(vetor_descricao.astype('float64'), axis=0)\n",
    "avg_vetor_descricao = np.nanmean(vetor_descricao, axis=0)\n",
    "vetor_genero_masc_skip100.append(avg_vetor_descricao)\n",
    "vetor_genero_masc_skip100 = np.array(vetor_genero_masc_skip100)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#MASC SKIP300\n",
    "vetor_genero_masc_skip300 = []\n",
    "\n",
    "vetor_descricao = np.empty([len(masculino), 300])\n",
    "vetor_descricao[:] = np.nan\n",
    "for j in range(len(masculino)):\n",
    "    if feminino[j] in model_skip300.key_to_index:\n",
    "        vetor_descricao[j] = model_skip300[masculino[j]].astype('float64')\n",
    "    else:\n",
    "        vetor_descricao[j] = np.empty((1,300))\n",
    "avg_vetor_descricao = np.nanmean(vetor_descricao.astype('float64'), axis=0)\n",
    "avg_vetor_descricao = np.nanmean(vetor_descricao, axis=0)\n",
    "vetor_genero_masc_skip300.append(avg_vetor_descricao)\n",
    "vetor_genero_masc_skip300 = np.array(vetor_genero_masc_skip300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cálculo da similaridade por cosseno\n",
    "\n",
    "from numpy.linalg import norm\n",
    "\n",
    "\n",
    "#CBOW50 FEMININO\n",
    "vetor_fem = []\n",
    "for i in range(len(df[\"vetor_cbow50\"])):\n",
    "    similaridade_fem = np.dot(vetor_genero_fem_cbow50, df[\"vetor_cbow50\"][i])/(norm(vetor_genero_fem_cbow50, axis=1)*norm(df[\"vetor_cbow50\"][i]))\n",
    "    vetor_fem.append(similaridade_fem)\n",
    "df[\"cosine_cbow50_fem\"] = pd.Series(vetor_fem).values\n",
    "\n",
    "#CBOW50 MASCULINO\n",
    "vetor_masc = []\n",
    "for i in range(len(df[\"vetor_cbow50\"])):\n",
    "    similaridade_masc = np.dot(vetor_genero_masc_cbow50, df[\"vetor_cbow50\"][i])/(norm(vetor_genero_masc_cbow50, axis=1)*norm(df[\"vetor_cbow50\"][i]))\n",
    "    vetor_masc.append(similaridade_masc)\n",
    "df[\"cosine_cbow50_masc\"] = pd.Series(vetor_masc).values\n",
    "\n",
    "\n",
    "\n",
    "#CBOW100 FEMININO\n",
    "vetor_fem = []\n",
    "for i in range(len(df[\"vetor_cbow100\"])):\n",
    "    similaridade_fem = np.dot(vetor_genero_fem_cbow100, df[\"vetor_cbow100\"][i])/(norm(vetor_genero_fem_cbow100, axis=1)*norm(df[\"vetor_cbow100\"][i]))\n",
    "    vetor_fem.append(similaridade_fem)\n",
    "df[\"cosine_cbow100_fem\"] = pd.Series(vetor_fem).values\n",
    "\n",
    "#CBOW100 MASCULINO\n",
    "vetor_masc = []\n",
    "for i in range(len(df[\"vetor_cbow100\"])):\n",
    "    similaridade_masc = np.dot(vetor_genero_masc_cbow100, df[\"vetor_cbow100\"][i])/(norm(vetor_genero_masc_cbow100, axis=1)*norm(df[\"vetor_cbow100\"][i]))\n",
    "    vetor_masc.append(similaridade_masc)\n",
    "df[\"cosine_cbow100_masc\"] = pd.Series(vetor_masc).values\n",
    "\n",
    "\n",
    "\n",
    "#CBOW300 FEMININO\n",
    "vetor_fem = []\n",
    "for i in range(len(df[\"vetor_cbow300\"])):\n",
    "    similaridade_fem = np.dot(vetor_genero_fem_cbow300, df[\"vetor_cbow300\"][i])/(norm(vetor_genero_fem_cbow300, axis=1)*norm(df[\"vetor_cbow300\"][i]))\n",
    "    vetor_fem.append(similaridade_fem)\n",
    "df[\"cosine_cbow300_fem\"] = pd.Series(vetor_fem).values\n",
    "\n",
    "#CBOW300 MASCULINO\n",
    "vetor_masc = []\n",
    "for i in range(len(df[\"vetor_cbow300\"])):\n",
    "    similaridade_masc = np.dot(vetor_genero_masc_cbow300, df[\"vetor_cbow300\"][i])/(norm(vetor_genero_masc_cbow300, axis=1)*norm(df[\"vetor_cbow300\"][i]))\n",
    "    vetor_masc.append(similaridade_masc)\n",
    "df[\"cosine_cbow300_masc\"] = pd.Series(vetor_masc).values\n",
    "\n",
    "\n",
    "\n",
    "#SKIP50 FEMININO\n",
    "vetor_fem = []\n",
    "for i in range(len(df[\"vetor_skip50\"])):\n",
    "    similaridade_fem = np.dot(vetor_genero_fem_skip50, df[\"vetor_skip50\"][i])/(norm(vetor_genero_fem_skip50, axis=1)*norm(df[\"vetor_skip50\"][i]))\n",
    "    vetor_fem.append(similaridade_fem)\n",
    "df[\"cosine_skip50_fem\"] = pd.Series(vetor_fem).values\n",
    "\n",
    "#SKIP50 MASCULINO\n",
    "vetor_masc = []\n",
    "for i in range(len(df[\"vetor_skip50\"])):\n",
    "    similaridade_masc = np.dot(vetor_genero_masc_skip50, df[\"vetor_skip50\"][i])/(norm(vetor_genero_masc_skip50, axis=1)*norm(df[\"vetor_skip50\"][i]))\n",
    "    vetor_masc.append(similaridade_masc)\n",
    "df[\"cosine_skip50_masc\"] = pd.Series(vetor_masc).values\n",
    "\n",
    "\n",
    "\n",
    "#SKIP100 FEMININO\n",
    "vetor_fem = []\n",
    "for i in range(len(df[\"vetor_skip100\"])):\n",
    "    similaridade_fem = np.dot(vetor_genero_fem_skip100, df[\"vetor_skip100\"][i])/(norm(vetor_genero_fem_skip100, axis=1)*norm(df[\"vetor_skip100\"][i]))\n",
    "    vetor_fem.append(similaridade_fem)\n",
    "df[\"cosine_skip100_fem\"] = pd.Series(vetor_fem).values\n",
    "\n",
    "#SKIP100 MASCULINO\n",
    "vetor_masc = []\n",
    "for i in range(len(df[\"vetor_skip100\"])):\n",
    "    similaridade_masc = np.dot(vetor_genero_masc_skip100, df[\"vetor_skip100\"][i])/(norm(vetor_genero_masc_skip100, axis=1)*norm(df[\"vetor_skip100\"][i]))\n",
    "    vetor_masc.append(similaridade_masc)\n",
    "df[\"cosine_skip100_masc\"] = pd.Series(vetor_masc).values\n",
    "\n",
    "\n",
    "\n",
    "#SKIP300 FEMININO\n",
    "vetor_fem = []\n",
    "for i in range(len(df[\"vetor_skip300\"])):\n",
    "    similaridade_fem = np.dot(vetor_genero_fem_skip300, df[\"vetor_skip300\"][i])/(norm(vetor_genero_fem_skip300, axis=1)*norm(df[\"vetor_skip300\"][i]))\n",
    "    vetor_fem.append(similaridade_fem)\n",
    "df[\"cosine_skip300_fem\"] = pd.Series(vetor_fem).values\n",
    "\n",
    "#SKIP300 MASCULINO\n",
    "vetor_masc = []\n",
    "for i in range(len(df[\"vetor_skip300\"])):\n",
    "    similaridade_masc = np.dot(vetor_genero_masc_skip300, df[\"vetor_skip300\"][i])/(norm(vetor_genero_masc_skip300, axis=1)*norm(df[\"vetor_skip300\"][i]))\n",
    "    vetor_masc.append(similaridade_masc)\n",
    "df[\"cosine_skip300_masc\"] = pd.Series(vetor_masc).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reordenando as colunas\n",
    "\n",
    "df = df[['Data_Publicacao',\n",
    "'Descricao',\n",
    "'Empresa',\n",
    "'Funcao',\n",
    "'Localidade',\n",
    "'Nivel_experiencia',\n",
    "'Plataforma',\n",
    "'Setor',\n",
    "'Tipo_emprego',\n",
    "'Titulo',\n",
    "'cosine_cbow50_fem',\n",
    "'cosine_cbow50_masc',\n",
    "'cosine_cbow100_fem',\n",
    "'cosine_cbow100_masc',\n",
    "'cosine_cbow300_fem',\n",
    "'cosine_cbow300_masc',\n",
    "'cosine_skip50_fem',\n",
    "'cosine_skip50_masc',\n",
    "'cosine_skip100_fem',\n",
    "'cosine_skip100_masc',\n",
    "'cosine_skip300_fem',\n",
    "'cosine_skip300_masc',\n",
    "'vetor_cbow50',\n",
    "'vetor_cbow100',\n",
    "'vetor_cbow300',\n",
    "'vetor_skip50',\n",
    "'vetor_skip100',\n",
    "'vetor_skip300']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Avaliando consistência entre as arquiteturas (CBOW e Skip-gram)\n",
    "\n",
    "# Criando coluna de similaridades médias para cada arquitetura\n",
    "\n",
    "df[\"cbow_fem_avg\"] = df[['cosine_cbow50_fem', 'cosine_cbow100_fem', 'cosine_cbow300_fem']].mean(axis=1)\n",
    "df[\"skip_fem_avg\"] = df[['cosine_skip50_fem', 'cosine_skip100_fem', 'cosine_skip300_fem']].mean(axis=1)\n",
    "\n",
    "df[\"cbow_masc_avg\"] = df[['cosine_cbow50_masc', 'cosine_cbow100_masc', 'cosine_cbow300_masc']].mean(axis=1)\n",
    "df[\"skip_masc_avg\"] = df[['cosine_skip50_masc', 'cosine_skip100_masc', 'cosine_skip300_masc']].mean(axis=1)\n",
    "\n",
    "\n",
    "# Criando coluna para validar consistência entre arquiteturas: Se CBOW e Skip-gram de determinado gênero apontam para a mesma direção = 1; senão = 0.\n",
    "\n",
    "df['valida_modelo'] = np.where((df['cbow_fem_avg'] >= df['cbow_masc_avg']) & (df['skip_fem_avg'] >= df['skip_masc_avg'])\n",
    "                               | (df['cbow_masc_avg'] >= df['cbow_fem_avg']) & (df['skip_masc_avg'] >= df['skip_fem_avg']), 1, 0)\n",
    "df.head(100)\n",
    "\n",
    "# df['valida_modelo'].value_counts(normalize=True)\n",
    "df['valida_modelo'].value_counts(normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Avaliando equilíbrio entre os gêneros (Fem e Masc)\n",
    "\n",
    "# Criando condicionais para avaliar gênero predominante (somente para as vagas consistentes entre as arquiteturas)\n",
    "conditions = [\n",
    "    df['valida_modelo'] == 0,\n",
    "    df['valida_modelo'] == 1 & ( df['cbow_fem_avg'] >= df['cbow_masc_avg']) & (df['skip_fem_avg'] >= df['skip_masc_avg']),\n",
    "    df['valida_modelo'] == 1 & (df['cbow_masc_avg'] >= df['cbow_fem_avg']) & (df['skip_masc_avg'] >= df['skip_fem_avg']),\n",
    "    ]\n",
    "\n",
    "values = [0, \"Fem\", \"Masc\"]\n",
    "\n",
    "df['magnitude'] = np.select(conditions, values)\n",
    "df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df['valida_modelo'] == 1\n",
    "# df[mask]['magnitude'].value_counts(normalize=True)\n",
    "df[mask]['magnitude'].value_counts(normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análise dos desvios-padrão das similaridades por cosseno entre as dimensionalidades de uma mesma arquitetura e gênero\n",
    "\n",
    "# Dados para Tabela 3\n",
    "\n",
    "df['std_cbow_fem'] = np.nan\n",
    "df['std_cbow_masc'] = np.nan\n",
    "df['std_skip_fem'] = np.nan\n",
    "df['std_skip_masc'] = np.nan\n",
    "\n",
    "for i in range(len(df)):\n",
    "    df['std_cbow_fem'][i] = np.std([df['cosine_cbow50_fem'][i], df['cosine_cbow100_fem'][i], df['cosine_cbow300_fem'][i]])\n",
    "    df['std_cbow_masc'][i] = np.std([df['cosine_cbow50_masc'][i], df['cosine_cbow100_masc'][i], df['cosine_cbow300_masc'][i]])\n",
    "    df['std_skip_fem'][i] = np.std([df['cosine_skip50_fem'][i], df['cosine_skip100_fem'][i], df['cosine_skip300_fem'][i]])\n",
    "    df['std_skip_masc'][i] = np.std([df['cosine_skip50_masc'][i], df['cosine_skip100_masc'][i], df['cosine_skip300_masc'][i]])\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ax = plt.axes()\n",
    "ax.scatter(df['cosine_cbow50_fem'], df['cosine_cbow50_masc'], label='50 dimensões', s=0.7, alpha=0.2)\n",
    "ax.scatter(df['cosine_cbow100_fem'], df['cosine_cbow100_masc'], label='100 dimensões', s=0.7, c='red', alpha=0.2)\n",
    "ax.scatter(df['cosine_cbow300_fem'], df['cosine_cbow300_masc'], label='300 dimensões', s=0.7, c='orange', alpha=0.2)\n",
    "ax.set_xlabel(\"Similaridade Vetor Feminino\")\n",
    "ax.set_ylabel(\"Similaridade Vetor Masculino\")\n",
    "plt.title('CBOW', loc='center')\n",
    "ax.set_xlim(-1, 1)\n",
    "ax.set_ylim(-1, 1)\n",
    "ax.axvline(x=0, c='black', linewidth=0.5)\n",
    "ax.axhline(y=0, c='black', linewidth=0.5)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "\n",
    "lgnd = ax.legend(loc='lower right')\n",
    "for handle in lgnd.legendHandles:\n",
    "    handle.set_sizes([30])\n",
    "    handle.set_alpha(1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ax = plt.axes()\n",
    "ax.scatter(df['cosine_skip50_fem'], df['cosine_skip50_masc'], label='50 dimensões', s=0.7, alpha=0.2)\n",
    "ax.scatter(df['cosine_skip100_fem'], df['cosine_skip100_masc'], label='100 dimensões', s=0.7, c='red', alpha=0.2)\n",
    "ax.scatter(df['cosine_skip300_fem'], df['cosine_skip300_masc'], label='300 dimensões', s=0.7, c='orange', alpha=0.2)\n",
    "ax.set_xlabel(\"Similaridade Vetor Feminino\")\n",
    "ax.set_ylabel(\"Similaridade Vetor Masculino\")\n",
    "plt.title('Skip-gram', loc='center')\n",
    "ax.set_xlim(-1, 1)\n",
    "ax.set_ylim(-1, 1)\n",
    "ax.axvline(x=0, c='black', linewidth=0.5)\n",
    "ax.axhline(y=0, c='black', linewidth=0.5)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "\n",
    "lgnd = ax.legend(loc='lower right')\n",
    "for handle in lgnd.legendHandles:\n",
    "    handle.set_sizes([30])\n",
    "    handle.set_alpha(1)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Teste vetores - inclusão pronomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_teste = pd.DataFrame()\n",
    "\n",
    "palavras_teste_masc = [\"ele\", \"dele\", \"nele\", \"este\", \"deste\", \"neste\", \"esse\", \"nesse\", \"aquele\", \"daquele\", \"naquele\", \"praquele\",\n",
    "                       \"eles\", \"deles\", \"neles\", \"estes\", \"destes\", \"nestes\", \"esses\", \"nesses\", \"aqueles\", \"daqueles\", \"naqueles\", \"praqueles\"]\n",
    "palavras_teste_fem = [\"ela\", \"dela\", \"nela\", \"esta\", \"desta\", \"nesta\", \"essa\", \"nessa\", \"aquela\", \"daquela\", \"naquela\", \"praquela\",\n",
    "                       \"elas\", \"delas\", \"nelas\", \"estas\", \"destas\", \"nestas\", \"essas\", \"nessas\", \"aquelas\", \"daquelas\", \"naquelas\", \"praquelas\"]\n",
    "\n",
    "df_teste[\"palavra_masc\"] = palavras_teste_masc\n",
    "df_teste[\"palavra_fem\"] = palavras_teste_fem\n",
    "\n",
    "vetor_avg = []\n",
    "\n",
    "for i in range(len(palavras_teste_masc)):\n",
    "    vetor_descricao = np.empty([len(palavras_teste_masc[i]), 300])\n",
    "    vetor_descricao[:] = np.nan\n",
    "    for j in range(len(palavras_teste_masc[i])):\n",
    "        if description[i][j] in model_cbow300.key_to_index:\n",
    "            vetor_descricao[j] = model_cbow300[palavras_teste_masc[i][j]].astype('float64')\n",
    "            # vetor_descricao.append(model[x].astype('float64'))\n",
    "        else:\n",
    "            # vetor_descricao.append(np.empty((1,50,)))\n",
    "            vetor_descricao[j] = np.empty((1,300,))\n",
    "    avg_vetor_descricao = np.nanmean(vetor_descricao.astype('float64'), axis=0)\n",
    "    avg_vetor_descricao = np.nanmean(vetor_descricao, axis=0)\n",
    "    # print(avg_vetor_descricao)\n",
    "    # df.vetor[i].append(avg_vetor_descricao)\n",
    "    vetor_avg.append(avg_vetor_descricao)\n",
    "\n",
    "df_teste[\"vetor_masc\"] = pd.Series(vetor_avg).values\n",
    "\n",
    "\n",
    "vetor_avg = []\n",
    "\n",
    "for i in range(len(palavras_teste_fem)):\n",
    "    vetor_descricao = np.empty([len(palavras_teste_fem[i]), 300])\n",
    "    vetor_descricao[:] = np.nan\n",
    "    for j in range(len(palavras_teste_fem[i])):\n",
    "        if description[i][j] in model_cbow300.key_to_index:\n",
    "            vetor_descricao[j] = model_cbow300[palavras_teste_fem[i][j]].astype('float64')\n",
    "            # vetor_descricao.append(model[x].astype('float64'))\n",
    "        else:\n",
    "            # vetor_descricao.append(np.empty((1,50,)))\n",
    "            vetor_descricao[j] = np.empty((1,300,))\n",
    "    avg_vetor_descricao = np.nanmean(vetor_descricao.astype('float64'), axis=0)\n",
    "    avg_vetor_descricao = np.nanmean(vetor_descricao, axis=0)\n",
    "    # print(avg_vetor_descricao)\n",
    "    # df.vetor[i].append(avg_vetor_descricao)\n",
    "    vetor_avg.append(avg_vetor_descricao)\n",
    "\n",
    "df_teste[\"vetor_fem\"] = pd.Series(vetor_avg).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criação dos vetores de gênero incluídos de pronomes\n",
    "\n",
    "df_teste.assign(cosine_cbow300_masc = np.nan, cosine_cbow300_fem = np.nan)\n",
    "\n",
    "#CBOW300 MASCULINO\n",
    "vetor_masc= []\n",
    "for i in range(len(df_teste[\"vetor_masc\"])):\n",
    "    similaridade_masc = np.dot(vetor_genero_masc_cbow300, df_teste[\"vetor_masc\"][i])/(norm(vetor_genero_masc_cbow300, axis=1)*norm(df_teste[\"vetor_masc\"][i]))\n",
    "    vetor_masc.append(similaridade_masc)\n",
    "df_teste[\"cosine_cbow300_masc\"] = pd.Series(vetor_masc).values\n",
    "\n",
    "#CBOW300 FEMININO\n",
    "vetor_fem = []\n",
    "for i in range(len(df_teste[\"vetor_fem\"])):\n",
    "    similaridade_fem = np.dot(vetor_genero_fem_cbow300, df_teste[\"vetor_fem\"][i])/(norm(vetor_genero_fem_cbow300, axis=1)*norm(df_teste[\"vetor_fem\"][i]))\n",
    "    vetor_fem.append(similaridade_fem)\n",
    "df_teste[\"cosine_cbow300_fem\"] = pd.Series(vetor_fem).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando as vagas com as 100 maiores similaridades para cada uma das arquiteturas e gêneros\n",
    "\n",
    "df2 = df[[\"Data_Publicacao\", \"Empresa\", \"Localidade\", \"Titulo\", \"cbow_fem_avg\", \"skip_fem_avg\", \"cbow_masc_avg\", \"skip_masc_avg\", \"valida_modelo\", \"magnitude\"]]\n",
    "\n",
    "cbow_h = df2.query(\"magnitude == 'Masc'\").sort_values(by = ['cbow_masc_avg'], ascending=False).head(100)\n",
    "skip_h = df2.query(\"magnitude == 'Masc'\").sort_values(by = ['skip_masc_avg'], ascending=False).head(100)\n",
    "\n",
    "cbow_m = df2.query(\"magnitude == 'Fem'\").sort_values(by = ['cbow_fem_avg'], ascending=False).head(100)\n",
    "skip_m = df2.query(\"magnitude == 'Fem'\").sort_values(by = ['skip_fem_avg'], ascending=False).head(100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testando como o aumento da dimensionalidade afeta a similaridade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = \"homem\"\n",
    "y = \"menino\"\n",
    "\n",
    "dist_cbow50 = np.dot(model_cbow50[y],model_cbow50[x])/(norm(model_cbow50[y])*norm(model_cbow50[x]))\n",
    "dist_cbow100 = np.dot(model_cbow100[y],model_cbow100[x])/(norm(model_cbow100[y])*norm(model_cbow100[x]))\n",
    "dist_cbow300 = np.dot(model_cbow300[y],model_cbow300[x])/(norm(model_cbow300[y])*norm(model_cbow300[x]))\n",
    "\n",
    "dist_skip50 = np.dot(model_skip50[y],model_skip50[x])/(norm(model_skip50[y])*norm(model_skip50[x]))\n",
    "dist_skip100 = np.dot(model_skip100[y],model_skip100[x])/(norm(model_skip100[y])*norm(model_skip100[x]))\n",
    "dist_skip300 = np.dot(model_skip300[y],model_skip300[x])/(norm(model_skip300[y])*norm(model_skip300[x]))\n",
    "\n",
    "print(\"Similaridade CBOW 50:\", dist_cbow50)\n",
    "print(\"Similaridade CBOW 100:\", dist_cbow100)\n",
    "print(\"Similaridade CBOW 300:\", dist_cbow300)\n",
    "print(\"Similaridade Skip-gram 50:\", dist_skip50)\n",
    "print(\"Similaridade Skip-gram 100:\", dist_skip100)\n",
    "print(\"Similaridade Skip-gram 300:\", dist_skip300)\n",
    "print(\"\")\n",
    "print(\"Média CBOW:\", np.mean([dist_cbow50, dist_cbow100, dist_cbow300]))\n",
    "print(\"Média Skip-gram:\", np.mean([dist_skip50, dist_skip100, dist_skip300]))\n",
    "print(\"Média Combinada\", np.mean([dist_cbow50, dist_cbow100, dist_cbow300, dist_skip50, dist_skip100, dist_skip300]))\n",
    "print(\"\")\n",
    "print(\"Desvio-padrão CBOW:\", np.std([dist_cbow50, dist_cbow100, dist_cbow300]))\n",
    "print(\"Desvio-padrão Skip-gram:\", np.std([dist_skip50, dist_skip100, dist_skip300]))\n",
    "print(\"Desvio-padrão Combinado\", np.std([dist_cbow50, dist_cbow100, dist_cbow300, dist_skip50, dist_skip100, dist_skip300]))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testando a similaridade entre os vetores de gênero e as palavras \"homem\"/\"mulher\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = \"mulher\"\n",
    "\n",
    "dist_cbow50 = np.dot(vetor_genero_fem_cbow50,model_cbow50[x])/(norm(vetor_genero_fem_cbow50)*norm(model_cbow50[x]))\n",
    "dist_cbow100 = np.dot(vetor_genero_fem_cbow100,model_cbow100[x])/(norm(vetor_genero_fem_cbow100)*norm(model_cbow100[x]))\n",
    "dist_cbow300 = np.dot(vetor_genero_fem_cbow300,model_cbow300[x])/(norm(vetor_genero_fem_cbow300)*norm(model_cbow300[x]))\n",
    "\n",
    "dist_skip50 = np.dot(vetor_genero_fem_skip50,model_skip50[x])/(norm(vetor_genero_fem_skip50)*norm(model_skip50[x]))\n",
    "dist_skip100 = np.dot(vetor_genero_fem_skip100,model_skip100[x])/(norm(vetor_genero_fem_skip100)*norm(model_skip100[x]))\n",
    "dist_skip300 = np.dot(vetor_genero_fem_skip300,model_skip300[x])/(norm(vetor_genero_fem_skip300)*norm(model_skip300[x]))\n",
    "\n",
    "print(\"Similaridade CBOW 50:\", dist_cbow50)\n",
    "print(\"Similaridade CBOW 100:\", dist_cbow100)\n",
    "print(\"Similaridade CBOW 300:\", dist_cbow300)\n",
    "print(\"Similaridade Skip-gram 50:\", dist_skip50)\n",
    "print(\"Similaridade Skip-gram 100:\", dist_skip100)\n",
    "print(\"Similaridade Skip-gram 300:\", dist_skip300)\n",
    "print(\"\")\n",
    "print(\"Média CBOW:\", np.mean([dist_cbow50, dist_cbow100, dist_cbow300]))\n",
    "print(\"Média Skip-gram:\", np.mean([dist_skip50, dist_skip100, dist_skip300]))\n",
    "print(\"Média Combinada\", np.mean([dist_cbow50, dist_cbow100, dist_cbow300, dist_skip50, dist_skip100, dist_skip300]))\n",
    "print(\"\")\n",
    "print(\"Desvio-padrão CBOW:\", np.std([dist_cbow50, dist_cbow100, dist_cbow300]))\n",
    "print(\"Desvio-padrão Skip-gram:\", np.std([dist_skip50, dist_skip100, dist_skip300]))\n",
    "print(\"Desvio-padrão Combinado\", np.std([dist_cbow50, dist_cbow100, dist_cbow300, dist_skip50, dist_skip100, dist_skip300]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = \"homem\"\n",
    "\n",
    "dist_cbow50 = np.dot(vetor_genero_masc_cbow50,model_cbow50[x])/(norm(vetor_genero_masc_cbow50)*norm(model_cbow50[x]))\n",
    "dist_cbow100 = np.dot(vetor_genero_masc_cbow100,model_cbow100[x])/(norm(vetor_genero_masc_cbow100)*norm(model_cbow100[x]))\n",
    "dist_cbow300 = np.dot(vetor_genero_masc_cbow300,model_cbow300[x])/(norm(vetor_genero_masc_cbow300)*norm(model_cbow300[x]))\n",
    "\n",
    "dist_skip50 = np.dot(vetor_genero_masc_skip50,model_skip50[x])/(norm(vetor_genero_masc_skip50)*norm(model_skip50[x]))\n",
    "dist_skip100 = np.dot(vetor_genero_masc_skip100,model_skip100[x])/(norm(vetor_genero_masc_skip100)*norm(model_skip100[x]))\n",
    "dist_skip300 = np.dot(vetor_genero_masc_skip300,model_skip300[x])/(norm(vetor_genero_masc_skip300)*norm(model_skip300[x]))\n",
    "\n",
    "print(\"Similaridade CBOW 50:\", dist_cbow50)\n",
    "print(\"Similaridade CBOW 100:\", dist_cbow100)\n",
    "print(\"Similaridade CBOW 300:\", dist_cbow300)\n",
    "print(\"Similaridade Skip-gram 50:\", dist_skip50)\n",
    "print(\"Similaridade Skip-gram 100:\", dist_skip100)\n",
    "print(\"Similaridade Skip-gram 300:\", dist_skip300)\n",
    "print(\"\")\n",
    "print(\"Média CBOW:\", np.mean([dist_cbow50, dist_cbow100, dist_cbow300]))\n",
    "print(\"Média Skip-gram:\", np.mean([dist_skip50, dist_skip100, dist_skip300]))\n",
    "print(\"Média Combinada\", np.mean([dist_cbow50, dist_cbow100, dist_cbow300, dist_skip50, dist_skip100, dist_skip300]))\n",
    "print(\"\")\n",
    "print(\"Desvio-padrão CBOW:\", np.std([dist_cbow50, dist_cbow100, dist_cbow300]))\n",
    "print(\"Desvio-padrão Skip-gram:\", np.std([dist_skip50, dist_skip100, dist_skip300]))\n",
    "print(\"Desvio-padrão Combinado\", np.std([dist_cbow50, dist_cbow100, dist_cbow300, dist_skip50, dist_skip100, dist_skip300]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testando se há viés de gênero nos vetores de palavras do NILC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_teste_modelo = pd.DataFrame()\n",
    "df_teste_modelo['palavras'] = model_cbow50.index_to_key\n",
    "\n",
    "listagem = []\n",
    "\n",
    "for i in range(len(df_teste_modelo)):\n",
    "    listagem.insert(i, model_cbow50[df_teste_modelo['palavras'][i]].astype('float64'))\n",
    "\n",
    "df_teste_modelo['vetor_cbow50'] = listagem\n",
    "\n",
    "mulher_cbow50 = model_cbow50[\"mulher\"]\n",
    "homem_cbow50 = model_cbow50[\"homem\"]\n",
    "\n",
    "df_teste_modelo[\"cosine_cbow50_fem\"] = np.nan\n",
    "df_teste_modelo[\"cosine_cbow50_masc\"] = np.nan\n",
    "\n",
    "for i in range(len(df_teste_modelo)):\n",
    "    df_teste_modelo['cosine_cbow50_fem'][i] = np.dot(mulher_cbow50, df_teste_modelo['vetor_cbow50'][i])/(norm(mulher_cbow50)*norm(df_teste_modelo['vetor_cbow50'][i]))\n",
    "    df_teste_modelo['cosine_cbow50_masc'][i] = np.dot(homem_cbow50, df_teste_modelo['vetor_cbow50'][i])/(norm(homem_cbow50)*norm(df_teste_modelo['vetor_cbow50'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_teste_modelo[df_teste_modelo[\"cosine_cbow50_fem\"]>=0])/len(df_teste_modelo))\n",
    "print(len(df_teste_modelo[df_teste_modelo[\"cosine_cbow50_masc\"]>=0])/len(df_teste_modelo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# sns.distplot(df_teste_modelo.similaridade_fem, axlabel = 'Similaridade', hist_kws=dict(alpha=0.3))\n",
    "# sns.distplot(df_teste_modelo.similaridade_masc, hist_kws=dict(alpha=0.3))\n",
    "\n",
    "sns.histplot(data=df_teste_modelo, x=\"cosine_cbow50_fem\", kde=True, color=\"lightskyblue\", alpha=0.4)\n",
    "sns.histplot(data=df_teste_modelo, x=\"cosine_cbow50_masc\", kde=True, color=\"orange\", alpha=0.4)\n",
    "\n",
    "plt.legend(['\"Mulher\"', '\"Homem\"'])\n",
    "plt.xlabel('Similaridade')\n",
    "plt.ylabel('Frequência')\n",
    "plt.title('CBOW-50', loc='center')\n",
    "plt.xlim([-1, 1])\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(df_teste_modelo.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando assimetria na distribuição das similaridades\n",
    "\n",
    "df_teste_modelo.skew(axis = 0, skipna = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando curtose na distribuição das similaridades\n",
    "\n",
    "df_teste_modelo.kurtosis(axis = 0, skipna = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verificando viés nas palavras das descrições"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cria dicionário somente com os tokens que são usados nas descrições\n",
    "\n",
    "i = 0\n",
    "j = 0\n",
    "dicionario = []\n",
    "\n",
    "for i in range(len(df.index)):\n",
    "    for j in range(len(description[i])):\n",
    "        dicionario.append(description[i][j])\n",
    "print(len(dicionario))\n",
    "dicionario = [*set(dicionario)]\n",
    "print(len(dicionario))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_teste_dicionario = df_teste_modelo\n",
    "df_teste_dicionario = df_teste_dicionario[df_teste_dicionario['palavras'].isin(dicionario)]\n",
    "\n",
    "print(len(df_teste_dicionario[df_teste_dicionario[\"cosine_cbow50_fem\"]>=0])/len(df_teste_dicionario))\n",
    "print(len(df_teste_dicionario[df_teste_dicionario[\"cosine_cbow50_masc\"]>=0])/len(df_teste_dicionario))\n",
    "\n",
    "# plt.hist(df_teste_dicionario[\"similaridade_fem\"], bins=20, alpha=0.45, color='blue')\n",
    "# plt.hist(df_teste_dicionario[\"similaridade_masc\"], bins=20, alpha=0.45, color='red')\n",
    "\n",
    "# sns.distplot(df_teste_dicionario.similaridade_fem, axlabel = 'Similaridade', hist_kws=dict(alpha=0.3))\n",
    "# sns.distplot(df_teste_dicionario.similaridade_masc, axlabel = 'Similaridade', hist_kws=dict(alpha=0.3))\n",
    "\n",
    "sns.histplot(data=df_teste_dicionario, x=\"cosine_cbow50_fem\", kde=True, color=\"lightskyblue\", alpha=0.4)\n",
    "sns.histplot(data=df_teste_dicionario, x=\"cosine_cbow50_masc\", kde=True, color=\"orange\", alpha=0.4)\n",
    "\n",
    "plt.legend(['\"Mulher\"', '\"Homem\"'])\n",
    "plt.xlabel('Similaridade')\n",
    "plt.ylabel('Frequência')\n",
    "plt.title('CBOW-50', loc='center')\n",
    "plt.xlim([-1, 1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando assimetria na distribuição das similaridades\n",
    "\n",
    "df_teste_dicionario.skew(axis = 0, skipna = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando curtose na distribuição das similaridades\n",
    "\n",
    "df_teste_dicionario.kurtosis(axis = 0, skipna = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dicionario)\n",
    "print(len(dicionario))\n",
    "print(len(df_teste_dicionario))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.axes()\n",
    "ax.scatter(df_teste_dicionario['cosine_cbow50_fem'], df_teste_dicionario['cosine_cbow50_masc'], s=0.7)\n",
    "ax.set_xlabel(\"Similaridade 'Mulher'\")\n",
    "ax.set_ylabel(\"Similaridade 'Homem'\")\n",
    "ax.set_xlim(-1, 1)\n",
    "ax.set_ylim(-1, 1)\n",
    "ax.axvline(x=0, c='black', linewidth=0.5)\n",
    "ax.axhline(y=0, c='black', linewidth=0.5)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testando se há viés no repositório do NILC (CBOW100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_teste_modelo['palavras_cbow100'] = model_cbow100.index_to_key\n",
    "\n",
    "listagem = []\n",
    "\n",
    "for i in range(len(df_teste_modelo)):\n",
    "    listagem.insert(i, model_cbow100[df_teste_modelo['palavras_cbow100'][i]].astype('float64'))\n",
    "\n",
    "df_teste_modelo['vetor_cbow100'] = listagem\n",
    "\n",
    "mulher_cbow100 = model_cbow100[\"mulher\"]\n",
    "homem_cbow100 = model_cbow100[\"homem\"]\n",
    "\n",
    "df_teste_modelo[\"cosine_cbow100_fem\"] = np.nan\n",
    "df_teste_modelo[\"cosine_cbow100_masc\"] = np.nan\n",
    "\n",
    "for i in range(len(df_teste_modelo)):\n",
    "    df_teste_modelo['cosine_cbow100_fem'][i] = np.dot(mulher_cbow100, df_teste_modelo['vetor_cbow100'][i])/(norm(mulher_cbow100)*norm(df_teste_modelo['vetor_cbow100'][i]))\n",
    "    df_teste_modelo['cosine_cbow100_masc'][i] = np.dot(homem_cbow100, df_teste_modelo['vetor_cbow100'][i])/(norm(homem_cbow100)*norm(df_teste_modelo['vetor_cbow100'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_teste_modelo[df_teste_modelo[\"cosine_cbow100_fem\"]>=0])/len(df_teste_modelo))\n",
    "print(len(df_teste_modelo[df_teste_modelo[\"cosine_cbow100_masc\"]>=0])/len(df_teste_modelo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.distplot(df_teste_modelo.similaridade_fem, axlabel = 'Similaridade', hist_kws=dict(alpha=0.3))\n",
    "# sns.distplot(df_teste_modelo.similaridade_masc, hist_kws=dict(alpha=0.3))\n",
    "\n",
    "sns.histplot(data=df_teste_modelo, x=\"cosine_cbow100_fem\", kde=True, color=\"lightskyblue\", alpha=0.4)\n",
    "sns.histplot(data=df_teste_modelo, x=\"cosine_cbow100_masc\", kde=True, color=\"orange\", alpha=0.4)\n",
    "\n",
    "plt.legend(['\"Mulher\"', '\"Homem\"'])\n",
    "plt.xlabel('Similaridade')\n",
    "plt.ylabel('Frequência')\n",
    "plt.title('CBOW-100', loc='center')\n",
    "plt.xlim([-1, 1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.distplot(df_teste_modelo.similaridade_fem, axlabel = 'Similaridade', hist_kws=dict(alpha=0.3))\n",
    "# sns.distplot(df_teste_modelo.similaridade_masc, hist_kws=dict(alpha=0.3))\n",
    "\n",
    "sns.histplot(data=df_teste_modelo, x=\"cosine_cbow50_fem\", kde=True, color=\"lightskyblue\", alpha=0.4)\n",
    "sns.histplot(data=df_teste_modelo, x=\"cosine_cbow50_masc\", kde=True, color=\"orange\", alpha=0.4)\n",
    "\n",
    "plt.legend(['\"Mulher\"', '\"Homem\"'])\n",
    "plt.xlabel('Similaridade')\n",
    "plt.ylabel('Frequência')\n",
    "plt.xlim([-1, 1])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_teste_dicionario = df_teste_modelo\n",
    "df_teste_dicionario = df_teste_dicionario[df_teste_dicionario['palavras'].isin(dicionario)]\n",
    "\n",
    "print(len(df_teste_dicionario[df_teste_dicionario[\"cosine_cbow100_fem\"]>=0])/len(df_teste_dicionario))\n",
    "print(len(df_teste_dicionario[df_teste_dicionario[\"cosine_cbow100_masc\"]>=0])/len(df_teste_dicionario))\n",
    "\n",
    "# plt.hist(df_teste_dicionario[\"similaridade_fem\"], bins=20, alpha=0.45, color='blue')\n",
    "# plt.hist(df_teste_dicionario[\"similaridade_masc\"], bins=20, alpha=0.45, color='red')\n",
    "\n",
    "# sns.distplot(df_teste_dicionario.similaridade_fem, axlabel = 'Similaridade', hist_kws=dict(alpha=0.3))\n",
    "# sns.distplot(df_teste_dicionario.similaridade_masc, axlabel = 'Similaridade', hist_kws=dict(alpha=0.3))\n",
    "\n",
    "sns.histplot(data=df_teste_dicionario, x=\"cosine_cbow100_fem\", kde=True, color=\"lightskyblue\", alpha=0.4)\n",
    "sns.histplot(data=df_teste_dicionario, x=\"cosine_cbow100_masc\", kde=True, color=\"orange\", alpha=0.4)\n",
    "\n",
    "plt.legend(['\"Mulher\"', '\"Homem\"'])\n",
    "plt.xlabel('Similaridade')\n",
    "plt.ylabel('Frequência')\n",
    "plt.title('CBOW-100', loc='center')\n",
    "plt.xlim([-1, 1])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.axes()\n",
    "ax.scatter(df_teste_dicionario['cosine_cbow50_fem'], df_teste_dicionario['cosine_cbow50_masc'], s=0.7, alpha=0.2)\n",
    "ax.scatter(df_teste_dicionario['cosine_cbow100_fem'], df_teste_dicionario['cosine_cbow100_masc'], s=0.7, c='red', alpha=0.2)\n",
    "ax.set_xlabel(\"Similaridade 'Mulher'\")\n",
    "ax.set_ylabel(\"Similaridade 'Homem'\")\n",
    "ax.set_xlim(-1, 1)\n",
    "ax.set_ylim(-1, 1)\n",
    "ax.axvline(x=0, c='black', linewidth=0.5)\n",
    "ax.axhline(y=0, c='black', linewidth=0.5)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testando se há viés no repositório do NILC (CBOW 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_teste_modelo['palavras'] = model_cbow300.index_to_key\n",
    "\n",
    "listagem = []\n",
    "\n",
    "for i in range(len(df_teste_modelo)):\n",
    "    listagem.insert(i, model_cbow300[df_teste_modelo['palavras'][i]].astype('float64'))\n",
    "\n",
    "df_teste_modelo['vetor_cbow300'] = listagem\n",
    "\n",
    "mulher_cbow300 = model_cbow300[\"mulher\"]\n",
    "homem_cbow300 = model_cbow300[\"homem\"]\n",
    "\n",
    "df_teste_modelo[\"cosine_cbow300_fem\"] = np.nan\n",
    "df_teste_modelo[\"cosine_cbow300_masc\"] = np.nan\n",
    "\n",
    "for i in range(len(df_teste_modelo)):\n",
    "    df_teste_modelo['cosine_cbow300_fem'][i] = np.dot(mulher_cbow300, df_teste_modelo['vetor_cbow300'][i])/(norm(mulher_cbow300)*norm(df_teste_modelo['vetor_cbow300'][i]))\n",
    "    df_teste_modelo['cosine_cbow300_masc'][i] = np.dot(homem_cbow300, df_teste_modelo['vetor_cbow300'][i])/(norm(homem_cbow300)*norm(df_teste_modelo['vetor_cbow300'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_teste_modelo[df_teste_modelo[\"cosine_cbow300_fem\"]>=0])/len(df_teste_modelo))\n",
    "print(len(df_teste_modelo[df_teste_modelo[\"cosine_cbow300_masc\"]>=0])/len(df_teste_modelo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.distplot(df_teste_modelo.similaridade_fem, axlabel = 'Similaridade', hist_kws=dict(alpha=0.3))\n",
    "# sns.distplot(df_teste_modelo.similaridade_masc, hist_kws=dict(alpha=0.3))\n",
    "\n",
    "sns.histplot(data=df_teste_modelo, x=\"cosine_cbow300_fem\", kde=True, color=\"lightskyblue\", alpha=0.4)\n",
    "sns.histplot(data=df_teste_modelo, x=\"cosine_cbow300_masc\", kde=True, color=\"orange\", alpha=0.4)\n",
    "\n",
    "plt.legend(['\"Mulher\"', '\"Homem\"'])\n",
    "plt.xlabel('Similaridade')\n",
    "plt.ylabel('Frequência')\n",
    "plt.title('CBOW-300', loc='center')\n",
    "plt.xlim([-1, 1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_teste_dicionario = df_teste_modelo\n",
    "df_teste_dicionario = df_teste_dicionario[df_teste_dicionario['palavras'].isin(dicionario)]\n",
    "\n",
    "print(len(df_teste_dicionario[df_teste_dicionario[\"cosine_cbow300_fem\"]>=0])/len(df_teste_dicionario))\n",
    "print(len(df_teste_dicionario[df_teste_dicionario[\"cosine_cbow300_masc\"]>=0])/len(df_teste_dicionario))\n",
    "\n",
    "# plt.hist(df_teste_dicionario[\"similaridade_fem\"], bins=20, alpha=0.45, color='blue')\n",
    "# plt.hist(df_teste_dicionario[\"similaridade_masc\"], bins=20, alpha=0.45, color='red')\n",
    "\n",
    "# sns.distplot(df_teste_dicionario.similaridade_fem, axlabel = 'Similaridade', hist_kws=dict(alpha=0.3))\n",
    "# sns.distplot(df_teste_dicionario.similaridade_masc, axlabel = 'Similaridade', hist_kws=dict(alpha=0.3))\n",
    "\n",
    "sns.histplot(data=df_teste_dicionario, x=\"cosine_cbow300_fem\", kde=True, color=\"lightskyblue\", alpha=0.4)\n",
    "sns.histplot(data=df_teste_dicionario, x=\"cosine_cbow300_masc\", kde=True, color=\"orange\", alpha=0.4)\n",
    "\n",
    "plt.legend(['\"Mulher\"', '\"Homem\"'])\n",
    "plt.xlabel('Similaridade')\n",
    "plt.ylabel('Frequência')\n",
    "plt.title('CBOW-300', loc='center')\n",
    "plt.xlim([-1, 1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.axes()\n",
    "ax.scatter(df_teste_dicionario['cosine_cbow50_fem'], df_teste_dicionario['cosine_cbow50_masc'], label='CBOW-50', s=0.7, alpha=0.2)\n",
    "ax.scatter(df_teste_dicionario['cosine_cbow100_fem'], df_teste_dicionario['cosine_cbow100_masc'], label='CBOW-100', s=0.7, c='red', alpha=0.2)\n",
    "ax.scatter(df_teste_dicionario['cosine_cbow300_fem'], df_teste_dicionario['cosine_cbow300_masc'], label='CBOW-300', s=0.7, c='orange', alpha=0.2)\n",
    "ax.set_xlabel(\"Similaridade 'Mulher'\")\n",
    "ax.set_ylabel(\"Similaridade 'Homem'\")\n",
    "ax.set_xlim(-1, 1)\n",
    "ax.set_ylim(-1, 1)\n",
    "ax.axvline(x=0, c='black', linewidth=0.5)\n",
    "ax.axhline(y=0, c='black', linewidth=0.5)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "\n",
    "lgnd = ax.legend(loc='lower right')\n",
    "for handle in lgnd.legendHandles:\n",
    "    handle.set_sizes([30])\n",
    "    handle.set_alpha(1)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testando se há viés no repositório do NILC e no dicionário (Skip-gram)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 50 Dimensões"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NILC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_teste_modelo['palavras'] = model_skip50.index_to_key\n",
    "\n",
    "listagem = []\n",
    "\n",
    "for i in range(len(df_teste_modelo)):\n",
    "    listagem.insert(i, model_skip50[df_teste_modelo['palavras'][i]].astype('float64'))\n",
    "\n",
    "df_teste_modelo['vetor_skip50'] = listagem\n",
    "\n",
    "mulher_skip50 = model_skip50[\"mulher\"]\n",
    "homem_skip50 = model_skip50[\"homem\"]\n",
    "\n",
    "df_teste_modelo[\"cosine_skip50_fem\"] = np.nan\n",
    "df_teste_modelo[\"cosine_skip50_masc\"] = np.nan\n",
    "\n",
    "for i in range(len(df_teste_modelo)):\n",
    "    df_teste_modelo['cosine_skip50_fem'][i] = np.dot(mulher_skip50, df_teste_modelo['vetor_skip50'][i])/(norm(mulher_skip50)*norm(df_teste_modelo['vetor_skip50'][i]))\n",
    "    df_teste_modelo['cosine_skip50_masc'][i] = np.dot(homem_skip50, df_teste_modelo['vetor_skip50'][i])/(norm(homem_skip50)*norm(df_teste_modelo['vetor_skip50'][i]))\n",
    "\n",
    "print(len(df_teste_modelo[df_teste_modelo[\"cosine_skip50_fem\"]>=0])/len(df_teste_modelo))\n",
    "print(len(df_teste_modelo[df_teste_modelo[\"cosine_skip50_masc\"]>=0])/len(df_teste_modelo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_teste_modelo[df_teste_modelo[\"cosine_skip50_fem\"]>=0])/len(df_teste_modelo))\n",
    "print(len(df_teste_modelo[df_teste_modelo[\"cosine_skip50_masc\"]>=0])/len(df_teste_modelo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.distplot(df_teste_modelo.similaridade_fem, axlabel = 'Similaridade', hist_kws=dict(alpha=0.3))\n",
    "# sns.distplot(df_teste_modelo.similaridade_masc, hist_kws=dict(alpha=0.3))\n",
    "\n",
    "sns.histplot(data=df_teste_modelo, x=\"cosine_skip50_fem\", kde=True, color=\"lightskyblue\", alpha=0.4)\n",
    "sns.histplot(data=df_teste_modelo, x=\"cosine_skip50_masc\", kde=True, color=\"orange\", alpha=0.4)\n",
    "\n",
    "plt.legend(['\"Mulher\"', '\"Homem\"'])\n",
    "plt.xlabel('Similaridade')\n",
    "plt.ylabel('Frequência')\n",
    "plt.title('Skip-gram-50', loc='center')\n",
    "plt.xlim([-1, 1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dicionário"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_teste_dicionario = df_teste_modelo\n",
    "df_teste_dicionario = df_teste_dicionario[df_teste_dicionario['palavras'].isin(dicionario)]\n",
    "\n",
    "print(len(df_teste_dicionario[df_teste_dicionario[\"cosine_skip50_fem\"]>=0])/len(df_teste_dicionario))\n",
    "print(len(df_teste_dicionario[df_teste_dicionario[\"cosine_skip50_masc\"]>=0])/len(df_teste_dicionario))\n",
    "\n",
    "# plt.hist(df_teste_dicionario[\"similaridade_fem\"], bins=20, alpha=0.45, color='blue')\n",
    "# plt.hist(df_teste_dicionario[\"similaridade_masc\"], bins=20, alpha=0.45, color='red')\n",
    "\n",
    "# sns.distplot(df_teste_dicionario.similaridade_fem, axlabel = 'Similaridade', hist_kws=dict(alpha=0.3))\n",
    "# sns.distplot(df_teste_dicionario.similaridade_masc, axlabel = 'Similaridade', hist_kws=dict(alpha=0.3))\n",
    "\n",
    "sns.histplot(data=df_teste_dicionario, x=\"cosine_skip50_fem\", kde=True, color=\"lightskyblue\", alpha=0.4)\n",
    "sns.histplot(data=df_teste_dicionario, x=\"cosine_skip50_masc\", kde=True, color=\"orange\", alpha=0.4)\n",
    "\n",
    "plt.legend(['\"Mulher\"', '\"Homem\"'])\n",
    "plt.xlabel('Similaridade')\n",
    "plt.ylabel('Frequência')\n",
    "plt.title('Skip-gram-50', loc='center')\n",
    "plt.xlim([-1, 1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 100 Dimensões"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NILC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_teste_modelo['palavras'] = model_skip100.index_to_key\n",
    "\n",
    "listagem = []\n",
    "\n",
    "for i in range(len(df_teste_modelo)):\n",
    "    listagem.insert(i, model_skip100[df_teste_modelo['palavras'][i]].astype('float64'))\n",
    "\n",
    "df_teste_modelo['vetor_skip100'] = listagem\n",
    "\n",
    "mulher_skip100 = model_skip100[\"mulher\"]\n",
    "homem_skip100 = model_skip100[\"homem\"]\n",
    "\n",
    "df_teste_modelo[\"cosine_skip100_fem\"] = np.nan\n",
    "df_teste_modelo[\"cosine_skip100_masc\"] = np.nan\n",
    "\n",
    "for i in range(len(df_teste_modelo)):\n",
    "    df_teste_modelo['cosine_skip100_fem'][i] = np.dot(mulher_skip100, df_teste_modelo['vetor_skip100'][i])/(norm(mulher_skip100)*norm(df_teste_modelo['vetor_skip100'][i]))\n",
    "    df_teste_modelo['cosine_skip100_masc'][i] = np.dot(homem_skip100, df_teste_modelo['vetor_skip100'][i])/(norm(homem_skip100)*norm(df_teste_modelo['vetor_skip100'][i]))\n",
    "\n",
    "print(len(df_teste_modelo[df_teste_modelo[\"cosine_skip100_fem\"]>=0])/len(df_teste_modelo))\n",
    "print(len(df_teste_modelo[df_teste_modelo[\"cosine_skip100_masc\"]>=0])/len(df_teste_modelo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_teste_modelo[df_teste_modelo[\"cosine_skip100_fem\"]>=0])/len(df_teste_modelo))\n",
    "print(len(df_teste_modelo[df_teste_modelo[\"cosine_skip100_masc\"]>=0])/len(df_teste_modelo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.distplot(df_teste_modelo.similaridade_fem, axlabel = 'Similaridade', hist_kws=dict(alpha=0.3))\n",
    "# sns.distplot(df_teste_modelo.similaridade_masc, hist_kws=dict(alpha=0.3))\n",
    "\n",
    "sns.histplot(data=df_teste_modelo, x=\"cosine_skip100_fem\", kde=True, color=\"lightskyblue\", alpha=0.4)\n",
    "sns.histplot(data=df_teste_modelo, x=\"cosine_skip100_masc\", kde=True, color=\"orange\", alpha=0.4)\n",
    "\n",
    "plt.legend(['\"Mulher\"', '\"Homem\"'])\n",
    "plt.xlabel('Similaridade')\n",
    "plt.ylabel('Frequência')\n",
    "plt.title('Skip-gram-100', loc='center')\n",
    "plt.xlim([-1, 1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dicionário"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_teste_dicionario = df_teste_modelo\n",
    "df_teste_dicionario = df_teste_dicionario[df_teste_dicionario['palavras'].isin(dicionario)]\n",
    "\n",
    "print(len(df_teste_dicionario[df_teste_dicionario[\"cosine_skip100_fem\"]>=0])/len(df_teste_dicionario))\n",
    "print(len(df_teste_dicionario[df_teste_dicionario[\"cosine_skip100_masc\"]>=0])/len(df_teste_dicionario))\n",
    "\n",
    "# plt.hist(df_teste_dicionario[\"similaridade_fem\"], bins=20, alpha=0.45, color='blue')\n",
    "# plt.hist(df_teste_dicionario[\"similaridade_masc\"], bins=20, alpha=0.45, color='red')\n",
    "\n",
    "# sns.distplot(df_teste_dicionario.similaridade_fem, axlabel = 'Similaridade', hist_kws=dict(alpha=0.3))\n",
    "# sns.distplot(df_teste_dicionario.similaridade_masc, axlabel = 'Similaridade', hist_kws=dict(alpha=0.3))\n",
    "\n",
    "sns.histplot(data=df_teste_dicionario, x=\"cosine_skip100_fem\", kde=True, color=\"lightskyblue\", alpha=0.4)\n",
    "sns.histplot(data=df_teste_dicionario, x=\"cosine_skip100_masc\", kde=True, color=\"orange\", alpha=0.4)\n",
    "\n",
    "plt.legend(['\"Mulher\"', '\"Homem\"'])\n",
    "plt.xlabel('Similaridade')\n",
    "plt.ylabel('Frequência')\n",
    "plt.title('Skip-gram-100', loc='center')\n",
    "plt.xlim([-1, 1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 300 Dimensões"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NILC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_teste_modelo['palavras'] = model_skip300.index_to_key\n",
    "\n",
    "listagem = []\n",
    "\n",
    "for i in range(len(df_teste_modelo)):\n",
    "    listagem.insert(i, model_skip300[df_teste_modelo['palavras'][i]].astype('float64'))\n",
    "\n",
    "df_teste_modelo['vetor_skip300'] = listagem\n",
    "\n",
    "mulher_skip300 = model_skip300[\"mulher\"]\n",
    "homem_skip300 = model_skip300[\"homem\"]\n",
    "\n",
    "df_teste_modelo[\"cosine_skip300_fem\"] = np.nan\n",
    "df_teste_modelo[\"cosine_skip300_masc\"] = np.nan\n",
    "\n",
    "for i in range(len(df_teste_modelo)):\n",
    "    df_teste_modelo['cosine_skip300_fem'][i] = np.dot(mulher_skip300, df_teste_modelo['vetor_skip300'][i])/(norm(mulher_skip300)*norm(df_teste_modelo['vetor_skip300'][i]))\n",
    "    df_teste_modelo['cosine_skip300_masc'][i] = np.dot(homem_skip300, df_teste_modelo['vetor_skip300'][i])/(norm(homem_skip300)*norm(df_teste_modelo['vetor_skip300'][i]))\n",
    "\n",
    "print(len(df_teste_modelo[df_teste_modelo[\"cosine_skip300_fem\"]>=0])/len(df_teste_modelo))\n",
    "print(len(df_teste_modelo[df_teste_modelo[\"cosine_skip300_masc\"]>=0])/len(df_teste_modelo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_teste_modelo[df_teste_modelo[\"cosine_skip300_fem\"]>=0])/len(df_teste_modelo))\n",
    "print(len(df_teste_modelo[df_teste_modelo[\"cosine_skip300_masc\"]>=0])/len(df_teste_modelo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.distplot(df_teste_modelo.similaridade_fem, axlabel = 'Similaridade', hist_kws=dict(alpha=0.3))\n",
    "# sns.distplot(df_teste_modelo.similaridade_masc, hist_kws=dict(alpha=0.3))\n",
    "\n",
    "sns.histplot(data=df_teste_modelo, x=\"cosine_skip300_fem\", kde=True, color=\"lightskyblue\", alpha=0.4)\n",
    "sns.histplot(data=df_teste_modelo, x=\"cosine_skip300_masc\", kde=True, color=\"orange\", alpha=0.4)\n",
    "\n",
    "plt.legend(['\"Mulher\"', '\"Homem\"'])\n",
    "plt.xlabel('Similaridade')\n",
    "plt.ylabel('Frequência')\n",
    "plt.title('Skip-gram-300', loc='center')\n",
    "plt.xlim([-1, 1])\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(df_teste_modelo.describe())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dicionário"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_teste_dicionario = df_teste_modelo\n",
    "df_teste_dicionario = df_teste_dicionario[df_teste_dicionario['palavras'].isin(dicionario)]\n",
    "\n",
    "print(len(df_teste_dicionario[df_teste_dicionario[\"cosine_skip300_fem\"]>=0])/len(df_teste_dicionario))\n",
    "print(len(df_teste_dicionario[df_teste_dicionario[\"cosine_skip300_masc\"]>=0])/len(df_teste_dicionario))\n",
    "\n",
    "# plt.hist(df_teste_dicionario[\"similaridade_fem\"], bins=20, alpha=0.45, color='blue')\n",
    "# plt.hist(df_teste_dicionario[\"similaridade_masc\"], bins=20, alpha=0.45, color='red')\n",
    "\n",
    "# sns.distplot(df_teste_dicionario.similaridade_fem, axlabel = 'Similaridade', hist_kws=dict(alpha=0.3))\n",
    "# sns.distplot(df_teste_dicionario.similaridade_masc, axlabel = 'Similaridade', hist_kws=dict(alpha=0.3))\n",
    "\n",
    "sns.histplot(data=df_teste_dicionario, x=\"cosine_skip300_fem\", kde=True, color=\"lightskyblue\", alpha=0.4)\n",
    "sns.histplot(data=df_teste_dicionario, x=\"cosine_skip300_masc\", kde=True, color=\"orange\", alpha=0.4)\n",
    "\n",
    "plt.legend(['\"Mulher\"', '\"Homem\"'])\n",
    "plt.xlabel('Similaridade')\n",
    "plt.ylabel('Frequência')\n",
    "plt.title('Skip-gram-300', loc='center')\n",
    "plt.xlim([-1, 1])\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(df_teste_dicionario.describe())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparativo Dimensões"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = plt.axes()\n",
    "ax.scatter(df_teste_dicionario['cosine_skip50_fem'], df_teste_dicionario['cosine_skip50_masc'], label='Skip-gram-50', s=0.7, alpha=0.2)\n",
    "ax.scatter(df_teste_dicionario['cosine_skip100_fem'], df_teste_dicionario['cosine_skip100_masc'], label='Skip-gram-100', s=0.7, c='red', alpha=0.2)\n",
    "ax.scatter(df_teste_dicionario['cosine_skip300_fem'], df_teste_dicionario['cosine_skip300_masc'], label='Skip-gram-300', s=0.7, c='orange', alpha=0.2)\n",
    "ax.set_xlabel(\"Similaridade 'Mulher'\")\n",
    "ax.set_ylabel(\"Similaridade 'Homem'\")\n",
    "ax.set_xlim(-1, 1)\n",
    "ax.set_ylim(-1, 1)\n",
    "ax.axvline(x=0, c='black', linewidth=0.5)\n",
    "ax.axhline(y=0, c='black', linewidth=0.5)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['bottom'].set_visible(False)\n",
    "ax.spines['left'].set_visible(False)\n",
    "\n",
    "lgnd = ax.legend(loc='lower right')\n",
    "for handle in lgnd.legendHandles:\n",
    "    handle.set_sizes([30])\n",
    "    handle.set_alpha(1)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
